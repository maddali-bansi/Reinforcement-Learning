{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be499589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cf8d19-061b-436a-8bfd-6d1f5cadc981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mujoco-py==0.5.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71facd25-6f5d-4f25-9af0-780de8ff3d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pyglet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdb7b11-7165-4700-8c76-a3966a052162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install Cython"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46578708-92e0-49de-a061-e0c613c62a35",
   "metadata": {},
   "source": [
    "Depedencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3bffde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import os\n",
    "import stable_baselines3\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.evaluation import evaluate_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870de8ba-bfb6-4cff-9481-3fcb674de637",
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = 'CartPole-v0'\n",
    "env = gym.make(environment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840a37f5-faea-4997-ad23-cdee995e17b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 5\n",
    "for episode in range(1, episodes+1):\n",
    "    state = env.reset()\n",
    "    print(f\"State = {state}\")\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        n_state,reward,done,info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode,score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca136fa-e677-4aa1-805e-5ea2c6936233",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b4b143-7698-4122-b3a4-33a5a6271e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea38f4e5-fcf1-4f84-a612-babdca005f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "log_path = os.path.join('Training','logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f9132e-711a-4552-a7a0-640afc4037cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ab386d-f757-4f95-812a-e974c5ff27e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(environment_name)\n",
    "env = DummyVecEnv([lambda: env])\n",
    "model = PPO('MlpPolicy',env,verbose=1,tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcce965f-22cb-4fe3-910f-742f20b04277",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74614ef-0f96-457b-ba78-078c4de81634",
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_path = os.path.join('Training','Saved Models','PPO Model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34e9d08-1632-4e6e-832c-f5fcfe2da1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(PPO_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aa7c37-5619-483a-9326-34500a058d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78576940-b567-4c04-81e6-c08290b4f32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO.load(PPO_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60e88b3-86df-48cc-818c-48d8f5f86c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_policy(model,env,n_eval_episodes=10,render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e4dfee-1f0c-4a8b-9c1b-8b4bdfe7e389",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e9e1bf-2650-462a-8b26-24a367781a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 10\n",
    "for episode in range(1, episodes+1):\n",
    "    obs = env.reset()\n",
    "    print(f\"State = {obs}\")\n",
    "    done = False\n",
    "    score = 0\n",
    "    \n",
    "    while not done:\n",
    "        env.render()\n",
    "        action, _ = model.predict(obs)\n",
    "        obs,reward,done,info = env.step(action)\n",
    "        score+=reward\n",
    "    print('Episode:{} Score:{}'.format(episode,score))\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1827e68c-15d4-4d4c-9fc2-ec091f8e8f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir={log_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18673a6-9f95-445b-9d32-42768bf975fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d95bda3-b0be-450b-b9be-fd5482da1dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('Training','Saved Models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0991c2d2-5983-4f68-8a08-df5c8d3a09d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_callback = StopTrainingOnRewardThreshold(reward_threshold=200, verbose=1)\n",
    "eval_callback = EvalCallback(env, callback_on_new_best=stop_callback,eval_freq=10000,best_model_save_path=save_path,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2db2224-ce7f-497d-9450-df0fdf05ae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO('MlpPolicy',env,verbose=1,tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f09c000-d476-4c48-aaca-f315bbf5ee53",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=20000,callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd96202-b82f-4384-9990-2e520139501b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_arch = [dict(pi=[128,128,128,128], vf=[128,128,128,128])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0887275-5c3a-4d7c-ba6c-5619283aaf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf03470-adb6-49e2-8abd-7ee84f1eb94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO('MlpPolicy',env,verbose=1,tensorboard_log=log_path, policy_kwargs={'net_arch':new_arch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c691c6-8d12-45a4-8b57-87b03b2440a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=20000,callback=eval_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba2da7c-9fab-44d1-b6dc-4155b97ed1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19d4187-fe2e-4c0e-8831-e46d1d3fb4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN('MlpPolicy',env,verbose=1,tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbed086-e292-4c9a-9075-5ecc84db8f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac52b42-a28b-4cf8-ab3d-fb0ee2b8f2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30154c3f-353d-4815-8f9b-df3663b35f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5baddec-de26-484d-b687-fba640de030a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rf_stable]",
   "language": "python",
   "name": "conda-env-rf_stable-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
